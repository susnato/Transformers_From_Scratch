{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def first_block(string):\n",
    "    return re.split(\"\\nclass|\\ndef|\\n#|\\n@|\\nprint|\\nif\", string)[0].rstrip()\n",
    "\n",
    "def complete_code(pipe, prompt, max_length=64, num_completions=4, seed=1):\n",
    "    set_seed(seed)\n",
    "    gen_kwargs = {'temperature':0.4, 'top_p':0.95, 'top_k':0, 'num_beams':1, 'do_sample':True}\n",
    "    code_gens = generation(prompt, num_return_sequences=num_completions,\n",
    "                           max_length=max_length, **gen_kwargs)\n",
    "    code_strings = []\n",
    "    for code_gen in code_gens:\n",
    "        generated_code = first_block(code_gen['generated_text'][len(prompt):])\n",
    "        code_strings.append(generated_code)\n",
    "    print(('\\n'+'='*80+'\\n').join(code_strings))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CODEPARROT-SMALL(MINE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 19:01:18.103370: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 19:01:18.243171: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-06 19:01:18.243197: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-06 19:01:18.268673: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-02-06 19:01:18.726910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 19:01:18.726957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-06 19:01:18.726962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "model_ckpt = \"susnato/codeparrot-small-trained\"\n",
    "generation = pipeline(\"text-generation\", model=model_ckpt, tokenizer=\"susnato/codeparrot\",\n",
    "                      device=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    if a[1] == 0:\n",
      "        return a[1]\n",
      "    if a[1] == 0:\n",
      "        return a[1]\n",
      "    return a[1]\n",
      "================================================================================\n",
      "\n",
      "    return a\n",
      "================================================================================\n",
      "\n",
      "    return a\n",
      "================================================================================\n",
      "\n",
      "    if a.is_rect_by_name(a.rect_by_name):\n",
      "        return a.rect_by_name(a.rect_by_name)\n",
      "    elif\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\"\"\"def area_of_rectangle(a: float, b: float):\n",
    "    Return the area of the rectangle.\"\"\"'''\n",
    "complete_code(generation, prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    if b is None:\n",
      "        return b\n",
      "    return b\n",
      "================================================================================\n",
      "\n",
      "    return sum(a.shape[0], b.shape[1])\n",
      "================================================================================\n",
      "\n",
      "    return [a for a in b if a in b]\n",
      "================================================================================\n",
      "\n",
      "    if a in [a, b]:\n",
      "        return a\n",
      "    return a\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\"\"\"def sum(a, b):\n",
    "    Return the addition of a and b.\"\"\"'''\n",
    "complete_code(generation, prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CODEPARROT-SMALL"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "\n",
    "model_ckpt = \"transformersbook/codeparrot-small\"\n",
    "generation = pipeline(\"text-generation\", model=model_ckpt, device=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    return math.sqrt(a * b)\n",
      "================================================================================\n",
      "\n",
      "    return math.sqrt(a * b)\n",
      "================================================================================\n",
      "\n",
      "    return math.sqrt(a / b)\n",
      "================================================================================\n",
      "\n",
      "    return a * b\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\"\"\"def area_of_rectangle(a: float, b: float):\n",
    "    Return the area of the rectangle.\"\"\"'''\n",
    "complete_code(generation, prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    if not a or not b:\n",
      "        return 0\n",
      "    return a + b\n",
      "================================================================================\n",
      "\n",
      "    return sum(a, b)\n",
      "================================================================================\n",
      "\n",
      "    return a + b\n",
      "================================================================================\n",
      "\n",
      "    if not a or not b:\n",
      "        return 0\n",
      "    return a + b\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\"\"\"def sum(a, b):\n",
    "    Return the addition of a and b.\"\"\"'''\n",
    "complete_code(generation, prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    if not html:\n",
      "        return []\n",
      "    return [url for url in re.findall(r'<a href=\"(/[^/]+/videos/[^\"]+)\"', html)]\n",
      "================================================================================\n",
      "\n",
      "    return [url for url in re.findall(r'<a href=\"(.*?)\"', html)\n",
      "            if url]\n",
      "================================================================================\n",
      "\n",
      "    return re.findall(r'<a href=\"(.*?)\"', html)\n",
      "================================================================================\n",
      "\n",
      "    if not html:\n",
      "        return []\n",
      "    return re.findall(r'<a href=\"(.*?)\"', html)\n"
     ]
    }
   ],
   "source": [
    "prompt = '''def get_urls_from_html(html):\n",
    "    \"\"\"Get all embedded URLs in a HTML string\"\"\"'''\n",
    "complete_code(generation, prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/huggingface/transformers | /join | /tasks | https://huggingface.co/transformers | /inference-api | /distilbert-base-uncased | /dbmdz/bert-large-cased-finetuned-conll03-english | https://bigscience.huggingface.co/ | https://bigscience.huggingface.co/blog/t0 | https://medium.com/huggingface/distilbert-8cf3380435b5 | https://arxiv.org/abs/1811.06031 | https://arxiv.org/abs/1803.10631 | /coref | https://transformer.huggingface.co/\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_urls_from_html(html):\n",
    "    return [url for url in re.findall(r'<a href=\"(.*?)\"', html) if url]\n",
    "\n",
    "print(\" | \".join(get_urls_from_html(requests.get('https://hf.co/').text)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "CODEPARROT-BIG"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    return np.mean(a)\n",
      "================================================================================\n",
      "\n",
      "    return sum(a)/len(a)\n",
      "================================================================================\n",
      "\n",
      "    return np.mean(a)\n",
      "================================================================================\n",
      "\n",
      "    return np.mean(a)\n"
     ]
    }
   ],
   "source": [
    "model_ckpt = \"transformersbook/codeparrot\"\n",
    "generation = pipeline('text-generation', model = model_ckpt, device=0)\n",
    "\n",
    "prompt = '''# a function in native python:\n",
    "def mean(a):\n",
    "    return sum(a)/len(a)\n",
    "\n",
    "# the same function using numpy:\n",
    "import numpy as np\n",
    "def mean(a):'''\n",
    "\n",
    "complete_code(generation, prompt, max_length=64)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "clf = RandomForestClassifier(n_estimators=20)\n",
      "clf.fit(X, y)\n",
      "================================================================================\n",
      "\n",
      "clf = RandomForestClassifier(n_estimators=20)\n",
      "clf.fit(X, y)\n",
      "================================================================================\n",
      "\n",
      "clf = RandomForestClassifier(n_estimators=20)\n",
      "clf.fit(X, y)\n",
      "================================================================================\n",
      "\n",
      "clf = RandomForestClassifier(n_estimators=20)\n",
      "clf.fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "prompt = '''X = np.random.randn(100, 100)\n",
    "y = np.random.randint(0, 1, 100)\n",
    "\n",
    "#fit random classifier with 20 estimators'''\n",
    "\n",
    "complete_code(generation, prompt, max_length=96)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    return a + b\n",
      "__add__ = sum\n",
      "================================================================================\n",
      "\n",
      "    return a + b\n",
      "================================================================================\n",
      "\n",
      "    return a + b\n",
      "================================================================================\n",
      "\n",
      "    return a + b\n"
     ]
    }
   ],
   "source": [
    "prompt = '''\"\"\"def sum(a, b):\n",
    "    Return the addition of a and b.\"\"\"'''\n",
    "complete_code(generation, prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
